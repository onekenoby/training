{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training & Prediction part -> ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = 'data_simulation.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME', 'COGNOME', 'TELEFONO', 'CELLULARE', 'EMAIL', 'COMUNE', 'CAP', 'INDIRIZZO', 'CODICE_FISCALE', 'IBAN', 'COMUNE_NASCITA', 'NOME_AZIENDA', 'TIPO_AZIENDA', 'CODICE_FISCALE_AZIENDA', 'PARTITA_IVA_AZIENDA', \n",
    "                 'DOCUMENTAZIONE_PENSIONATO'], inplace=True)\n",
    "\n",
    "# Define the number of quantiles\n",
    "num_bins = 5\n",
    "# Segment the TFR variable into quantiles\n",
    "df['TFR_Category'] = pd.qcut(df['TFR'], q=num_bins, labels=[\n",
    "                             'Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "print(df['TFR'].dtypes)\n",
    "print(df['TFR_Category'].dtypes)\n",
    "\n",
    "# Define the number of quantiles\n",
    "num_bins = 5\n",
    "# Segment the TFR variable into quantiles\n",
    "df['TFR_Category'] = pd.qcut(df['TFR'], q=num_bins, labels=[\n",
    "                             'Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "print(df['TFR'].dtypes)\n",
    "print(df['TFR_Category'].dtypes)\n",
    "\n",
    "df['TFR_Category'], bins = pd.qcut(df['TFR'], q=num_bins, labels=['Molto Basso', 'Basso', 'Medio', 'Alto', 'Molto Alto'], retbins=True)\n",
    "\n",
    "for i in range(len(bins)-1):\n",
    "    # print(f\"{bins[i]} to {bins[i+1]} : {df['TFR_Category'].cat.categories[i]}\")\n",
    "    print(f\"{df['TFR_Category'].cat.categories[i]} : {bins[i]} to {bins[i+1]}\")\n",
    "    \n",
    "\n",
    "# Encode categorical variables\n",
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        encoders[column] = le\n",
    "print(encoders)\n",
    "\n",
    "\n",
    "df.drop(columns=['TFR'], inplace=True)\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Convert the importances into a DataFrame\n",
    "feature_importances = pd.DataFrame(\n",
    "    {'feature': X.columns, 'importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 8000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Architetto comunale',\n",
    "    'PROVINCIA': 'Genova',\n",
    "    'CONSENSO_DATI_PRIVACY': 1,\n",
    "    'CONSENSO_DATI_MRKTG': 1,\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 0,\n",
    "    'SESSO': 'F',\n",
    "    'REGIONE': 'Liguria',\n",
    "    'COMUNE': 'City1',\n",
    "    'CAP': '12345',\n",
    "    'COMUNE_NASCITA': 'BirthCity1',\n",
    "    'IMPORTO_STIPENDIO_PENSIONE': 2000,\n",
    "    'TFR_Category': \"Basso\",\n",
    "    'TIPO_AZIENDA': 'Pubblica',\n",
    "    'TEMPO_INDETERMINATO': 1,\n",
    "    'PREVENTIVI_CONCORRENZA': 0,\n",
    "    'TRATTENUTE_BUSTA_PAGA_PENSIONE': 0,\n",
    "    'ALTRI_FINANZIAMENTI_PRESENTI': 1\n",
    "}\n",
    "\n",
    "# Encode the new customer data using the fitted label encoders\n",
    "print(encoders)\n",
    "\n",
    "new_customer_encoded = {}\n",
    "\n",
    "for column in new_customer:\n",
    "    if column in encoders:\n",
    "        new_customer_encoded[column] = encoders[column].transform(\n",
    "            [new_customer[column]])[0]\n",
    "    else:\n",
    "        new_customer_encoded[column] = new_customer[column]\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_customer_df = pd.DataFrame([new_customer_encoded])\n",
    "\n",
    "# Ensure the new customer data has the same columns as the training data\n",
    "new_customer_df = new_customer_df.reindex(columns=X.columns)\n",
    "\n",
    "# Now you can make a prediction\n",
    "predicted_motivation = clf.predict(new_customer_df)\n",
    "\n",
    "predicted_motivation_label = encoders['MOTIVAZIONE_PRESTITO'].inverse_transform(\n",
    "    predicted_motivation)\n",
    "\n",
    "print(f\"Predicted loan motivation for the new customer: {predicted_motivation_label[0]}\")\n",
    "\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = clf.predict_proba(new_customer_df)\n",
    "\n",
    "# Convert the probabilities into a DataFrame\n",
    "probabilities_df = pd.DataFrame(\n",
    "    predicted_probabilities, columns=encoders['MOTIVAZIONE_PRESTITO'].classes_)\n",
    "\n",
    "print(\n",
    "    f\"Predicted loan motivation for the new customer: {predicted_motivation_label[0]}\")\n",
    "\n",
    "\n",
    "print(\"Probabilities for each class:\")\n",
    "print(probabilities_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Part -> ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TFR Categories and ranges\n",
      "Molto Basso: [7254.55 - 44498.392]\n",
      "Basso: [44498.392 - 72049.532]\n",
      "Medio: [72049.532 - 107007.01200000003]\n",
      "Alto: [107007.01200000003 - 160157.70800000004]\n",
      "Molto Alto: [160157.70800000004 - 310022.36]\n",
      "\n",
      "\n",
      "                           feature  importance\n",
      "2                        PROVINCIA    0.574415\n",
      "7                          REGIONE    0.164335\n",
      "8                     DATA_NASCITA    0.037997\n",
      "10  DATA_ ASSUNZIONE_PENSIONAMENTO    0.037807\n",
      "1              TIPO DI OCCUPAZIONE    0.031464\n",
      "0                IMPORTO_RICHIESTO    0.029168\n",
      "16                    TFR_Category    0.015333\n",
      "18        anni_lavorativi_Category    0.013752\n",
      "17                    AGE_Category    0.012249\n",
      "11                    TIPO_AZIENDA    0.012171\n",
      "9       IMPORTO_STIPENDIO_PENSIONE    0.011896\n",
      "13          PREVENTIVI_CONCORRENZA    0.007762\n",
      "14  TRATTENUTE_BUSTA_PAGA_PENSIONE    0.007644\n",
      "4              CONSENSO_DATI_MRKTG    0.007562\n",
      "15   ALTRI_FINANZIAMENTI_ PRESENTI    0.007533\n",
      "12             TEMPO_INDETERMINATO    0.007460\n",
      "6                            SESSO    0.007302\n",
      "3           CONSENSO_DATI_PRIVACY     0.007234\n",
      "5     CONSENSO_DATI_CESSIONE_TERZI    0.006914\n",
      "\n",
      "Accuracy: 0.9966666666666667\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        31\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      1.00      1.00        34\n",
      "           3       1.00      1.00      1.00        26\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        15\n",
      "           6       1.00      1.00      1.00        25\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       0.96      0.96      0.96        27\n",
      "           9       1.00      1.00      1.00        40\n",
      "          10       1.00      1.00      1.00        33\n",
      "          11       1.00      1.00      1.00        32\n",
      "          12       0.96      1.00      0.98        27\n",
      "          13       1.00      1.00      1.00        27\n",
      "          14       1.00      0.96      0.98        28\n",
      "          15       1.00      0.75      0.86        28\n",
      "          16       1.00      1.00      1.00        29\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       1.00      1.00      1.00      2495\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.99      0.98      0.99      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the function to categorize ages\n",
    "def categorize_age(age):\n",
    "    if 30 <= age <= 40:\n",
    "        return \"30-40\"\n",
    "    elif 41 <= age <= 50:\n",
    "        return \"41-50\"\n",
    "    elif 51 <= age <= 60:\n",
    "        return \"51-60\"\n",
    "    elif 61 <= age <= 70:\n",
    "        return \"61-70\"\n",
    "    else:\n",
    "        return \"Out of Range\"\n",
    "\n",
    "# Define the function to categorize working years\n",
    "\n",
    "\n",
    "def categorize_wrk_yrs(wrkyrs):\n",
    "    if 5 <= wrkyrs <= 10:\n",
    "        return \"5-10\"\n",
    "    elif 11 <= wrkyrs <= 20:\n",
    "        return \"11-20\"\n",
    "    elif 21 <= wrkyrs <= 30:\n",
    "        return \"21-30\"\n",
    "    elif 31 <= wrkyrs <= 40:\n",
    "        return \"31-40\"\n",
    "    elif 41 <= wrkyrs <= 45:\n",
    "        return \"41-45\"\n",
    "    else:\n",
    "        return \"Out of Range\"\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = 'data_simulation.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.columns\n",
    "\n",
    "# ########### TFR to DROP ###################\n",
    "# Define the number of quantiles\n",
    "#####################################\n",
    "num_bins = 5\n",
    "df['TFR_Category'], bins = pd.qcut(df['TFR'], q=num_bins, labels=['Molto Basso', 'Basso', 'Medio', 'Alto', 'Molto Alto'], retbins=True)\n",
    "#print(df['TFR'].dtypes)\n",
    "#print(df['TFR_Category'].dtypes)\n",
    "\n",
    "# Create a dictionary to store the range for each category\n",
    "category_ranges = {\n",
    "    'Molto Basso': (bins[0], bins[1]),\n",
    "    'Basso': (bins[1], bins[2]),\n",
    "    'Medio': (bins[2], bins[3]),\n",
    "    'Alto': (bins[3], bins[4]),\n",
    "    'Molto Alto': (bins[4], bins[5])\n",
    "}\n",
    "\n",
    "# Print the ranges for each category\n",
    "print(\"\\nTFR Categories and ranges\")\n",
    "for category, (low, high) in category_ranges.items():\n",
    "    print(f'{category}: [{low} - {high}]')\n",
    "\n",
    "\n",
    "# ########### AGE to DROP ###################\n",
    "# Define the classe base on categorize_age\n",
    "#####################################\n",
    "# Apply the function to the DataFrame to create a new column\n",
    "df['AGE_Category'] = df['AGE'].apply(categorize_age)\n",
    "\n",
    "\n",
    "# ########### anni lavorativi to DROP ###################\n",
    "# Define the classe base on categorize_age\n",
    "#####################################\n",
    "# Apply the function to the DataFrame to create a new column\n",
    "df['anni_lavorativi_Category'] = df['anni lavorativi'].apply(categorize_wrk_yrs)\n",
    "\n",
    "# besides, to drop are: TFR, AGE, anni lavorativi\n",
    "\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME',\n",
    "                 'COGNOME',\n",
    "                 'TELEFONO',\n",
    "                 'CELLULARE',\n",
    "                 'EMAIL',\n",
    "                 'COMUNE',\n",
    "                 'CAP',\n",
    "                 'INDIRIZZO',\n",
    "                 'CODICE_FISCALE',\n",
    "                 'IBAN',\n",
    "                 'COMUNE_NASCITA',\n",
    "                 'AGE',\n",
    "                 'anni lavorativi',\n",
    "                 'TFR',\n",
    "                 'NOME_AZIENDA',\n",
    "                 'CODICE_FISCALE_AZIENDA',\n",
    "                 'PARTITA_IVA_AZIENDA',\n",
    "                 'DOCUMENTAZIONE_PENSIONATO',\n",
    "                 'REGISTRAZIONE_TEL_PRIMO_CONTATTO',\n",
    "                 'NOTE_LAVORAZIONE_CONTATTO'\n",
    "                 ], inplace=True)\n",
    "\n",
    "df.columns\n",
    "#df.info()\n",
    "#df['AGE_Category']\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        encoders[column] = le\n",
    "#print(encoders)\n",
    "#df.info()\n",
    "#df['AGE_Category']\n",
    "\n",
    "\n",
    "#Random Forest to train the model\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Convert the importances into a DataFrame\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"\\n\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Part1 -> OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted loan motivation for the new customer: spese viaggi\n",
      "Predicted loan motivation for the new customer: spese viaggi\n",
      "Probabilities for each class:\n",
      "                             0\n",
      "Corsi/Specializzazioni     0.0\n",
      "Risarcimenti               0.0\n",
      "acquisto arredamento casa  0.0\n",
      "acquisto auto/moto         0.0\n",
      "acquisto immobili          0.0\n",
      "anticipo prima casa        0.0\n",
      "consolidamento debiti      0.0\n",
      "investimenti               0.0\n",
      "liquidità                  0.0\n",
      "non specificata            0.0\n",
      "pagamenti imposte e tasse  0.0\n",
      "rinegoziazione             0.0\n",
      "ristrutturazione casa      0.0\n",
      "spese dentistiche          0.0\n",
      "spese matrimoniali         0.0\n",
      "spese medico sanitarie     0.0\n",
      "spese per cerimonie        0.0\n",
      "spese universitarie        0.0\n",
      "spese viaggi               1.0\n"
     ]
    }
   ],
   "source": [
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 15000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Architetto comunale',\n",
    "    'PROVINCIA': 'Roma',\n",
    "    'CONSENSO_DATI_PRIVACY': 1,\n",
    "    'CONSENSO_DATI_MRKTG': 1,\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 0,\n",
    "    'SESSO': 'F',\n",
    "    'REGIONE': 'Lazio',\n",
    "    'IMPORTO_STIPENDIO_PENSIONE': 2000,\n",
    "    #'AGE_Category': '41-50',\n",
    "    'anni_lavorativi_Category': '21-30',\n",
    "    #'TFR_Category': \"Basso\",\n",
    "    #'TIPO_AZIENDA': 'Pubblica',\n",
    "    #'TEMPO_INDETERMINATO': 1,\n",
    "    #'PREVENTIVI_CONCORRENZA': 0,\n",
    "    #'TRATTENUTE_BUSTA_PAGA_PENSIONE': 0,\n",
    "    'ALTRI_FINANZIAMENTI_PRESENTI': 1\n",
    "}\n",
    "\n",
    "# encoding new_customer data\n",
    "new_customer_encoded = {}\n",
    "for column in new_customer:\n",
    "    if column in encoders:\n",
    "        new_customer_encoded[column] = encoders[column].transform(\n",
    "            [new_customer[column]])[0]\n",
    "    else:\n",
    "        new_customer_encoded[column] = new_customer[column]\n",
    "\n",
    "#print(new_customer_encoded)\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_customer_df = pd.DataFrame([new_customer_encoded])\n",
    "# Ensure the new customer data has the same columns as the training data\n",
    "new_customer_df = new_customer_df.reindex(columns=X.columns)\n",
    "# Now you can make a prediction\n",
    "predicted_motivation = clf.predict(new_customer_df)\n",
    "predicted_motivation_label = encoders['MOTIVAZIONE_PRESTITO'].inverse_transform(predicted_motivation)\n",
    "\n",
    "print(f\"Predicted loan motivation for the new customer: {predicted_motivation_label[0]}\")\n",
    "\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = clf.predict_proba(new_customer_df)\n",
    "\n",
    "# Convert the probabilities into a DataFrame\n",
    "probabilities_df = pd.DataFrame(\n",
    "    predicted_probabilities, columns=encoders['MOTIVAZIONE_PRESTITO'].classes_)\n",
    "\n",
    "print(\n",
    "    f\"Predicted loan motivation for the new customer: {predicted_motivation_label[0]}\")\n",
    "\n",
    "print(\"Probabilities for each class:\")\n",
    "print(probabilities_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Part2 -> flexible method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 15000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Architetto comunale',\n",
    "    'PROVINCIA': 'Roma',\n",
    "    'CONSENSO_DATI_PRIVACY': 1,\n",
    "    'CONSENSO_DATI_MRKTG': 1,\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 0,\n",
    "    # 'SESSO': 'F',\n",
    "    'REGIONE': 'Lazio',\n",
    "    # 'IMPORTO_STIPENDIO_PENSIONE': 2000,\n",
    "    # 'AGE_Category': '41-50',\n",
    "    'anni_lavorativi_Category': '21-30',\n",
    "    # 'TFR_Category': \"Basso\",\n",
    "    # 'TIPO_AZIENDA': 'Pubblica',\n",
    "    # 'TEMPO_INDETERMINATO': 1,\n",
    "    # 'PREVENTIVI_CONCORRENZA': 0,\n",
    "    # 'TRATTENUTE_BUSTA_PAGA_PENSIONE': 0,\n",
    "    'ALTRI_FINANZIAMENTI_PRESENTI': 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# encoding new_customer data\n",
    "new_customer_encoded = {}\n",
    "for column in new_customer:\n",
    "    if column in encoders:\n",
    "        new_customer_encoded[column] = encoders[column].transform(\n",
    "            [new_customer[column]])[0]\n",
    "    else:\n",
    "        new_customer_encoded[column] = new_customer[column]\n",
    "\n",
    "print(new_customer_encoded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_customer_encoded = {}\n",
    "# Fill in missing features with median or mode values\n",
    "for column in X.columns:\n",
    "    if column not in new_customer:\n",
    "        # If the column is numeric, fill with median value\n",
    "        if X[column].dtype in ['int64', 'float64']:\n",
    "            new_customer[column] = X[column].median()\n",
    "        # If the column is categorical, fill with mode value\n",
    "        else:\n",
    "            new_customer[column] = X[column].mode()[0]\n",
    "\n",
    "print(new_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# New customer profile with only three features\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 8000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Poliziotto',\n",
    "    'PROVINCIA': 'Roma'\n",
    "}\n",
    "\n",
    "new_customer_encoded = {}\n",
    "# Fill in missing features with median or mode values\n",
    "for column in X.columns:\n",
    "    if column not in new_customer:\n",
    "        # If the column is numeric, fill with median value\n",
    "        if X[column].dtype in ['int64', 'float64']:\n",
    "            new_customer[column] = X[column].median()\n",
    "        # If the column is categorical, fill with mode value\n",
    "        else:\n",
    "            new_customer[column] = X[column].mode()[0]\n",
    "\n",
    "print(new_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_customer)\n",
    "print(new_customer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select one of the trees in the forest\n",
    "selected_tree = clf.estimators_[0]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(4, 4), dpi=800)\n",
    "tree.plot_tree(selected_tree,\n",
    "               feature_names=X.columns,\n",
    "               class_names=encoders['MOTIVAZIONE_PRESTITO'].classes_,\n",
    "               filled=True)\n",
    "fig.savefig('rf_individualtree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "# Display the columns of the DataFrame\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# List of columns to be one-hot encoded\n",
    "categorical_columns = ['TIPO DI OCCUPAZIONE', 'PROVINCIA', 'SESSO','REGIONE', 'COMUNE', 'CAP', 'COMUNE_NASCITA', 'TIPO_AZIENDA']\n",
    "\n",
    "# Check if all the required columns are present in the DataFrame\n",
    "missing_columns = [col for col in categorical_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(\n",
    "        f\"The following columns are missing from the DataFrame and cannot be encoded: {missing_columns}\")\n",
    "else:\n",
    "    # One-hot encode the categorical variables\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "    # Standardize the features to have mean=0 and variance=1\n",
    "    features_standardized = StandardScaler().fit_transform(df_encoded)\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(features_standardized)\n",
    "    principalDf = pd.DataFrame(data=principalComponents, columns=[\n",
    "                               'principal component 1', 'principal component 2'])\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    clusters = kmeans.fit_predict(features_standardized)\n",
    "\n",
    "    # Add the cluster number to the principalDf\n",
    "    principalDf['Cluster'] = clusters\n",
    "\n",
    "    # Visualize the clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"principal component 1\", y=\"principal component 2\",\n",
    "                    hue=\"Cluster\", data=principalDf, palette=['red', 'blue', 'green'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=['TIPO DI OCCUPAZIONE', 'PROVINCIA','SESSO', 'REGIONE', 'COMUNE', 'CAP', 'COMUNE_NASCITA', 'TIPO_AZIENDA'])\n",
    "\n",
    "# Standardize the features to have mean=0 and variance=1\n",
    "features_standardized = StandardScaler().fit_transform(df_encoded)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(features_standardized)\n",
    "principalDf = pd.DataFrame(data=principalComponents, columns=[\n",
    "                           'principal component 1', 'principal component 2'])\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(features_standardized)\n",
    "\n",
    "# Add the cluster number to the principalDf\n",
    "principalDf['Cluster'] = clusters\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=\"principal component 1\", y=\"principal component 2\", hue=\"Cluster\", data=principalDf, palette=['red', 'blue', 'green'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the sum of squared distances for different numbers of clusters\n",
    "sum_of_squared_distances = []\n",
    "K = range(1, 15)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans = kmeans.fit(features_standardized)\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the sum of squared distances\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k (number of clusters)')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use PCA to reduce dimensionality so we can visualize the dataset on a 2D plot\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Concatenate the DataFrame with target labels\n",
    "df_pca = pd.concat([X_pca_df, y], axis=1)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 0, 'PC1'],\n",
    "            df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 0, 'PC2'], color='blue', alpha=0.5, label='Car')\n",
    "plt.scatter(df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 1, 'PC1'],\n",
    "            df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 1, 'PC2'], color='red', alpha=0.5, label='House')\n",
    "plt.scatter(df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 2, 'PC1'],\n",
    "            df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 2, 'PC2'], color='green', alpha=0.5, label='Vacation')\n",
    "plt.scatter(df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 3, 'PC1'],\n",
    "            df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 3, 'PC2'], color='purple', alpha=0.5, label='Business')\n",
    "plt.scatter(df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 4, 'PC1'],\n",
    "            df_pca.loc[df_pca['MOTIVAZIONE_PRESTITO'] == 4, 'PC2'], color='yellow', alpha=0.5, label='Education')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(features_standardized)\n",
    "\n",
    "# Convert the original data dictionary to a DataFrame\n",
    "df_original = pd.DataFrame(data)\n",
    "\n",
    "# Add the cluster assignments to the original DataFrame\n",
    "df_original['Cluster'] = clusters\n",
    "\n",
    "# Print the DataFrame with the cluster assignments\n",
    "print(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.rand(100)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Choose distance metric\n",
    "metric = 'euclidean'  # Change this to 'manhattan', 'minkowski', etc. euclidean\n",
    "\n",
    "# Perform Agglomerative Clustering\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=3, metric=metric, linkage='ward')\n",
    "labels = clustering.fit_predict(df)\n",
    "\n",
    "# Add cluster labels to DataFrame\n",
    "df['Cluster'] = labels\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Feature1', y='Feature2',\n",
    "                hue='Cluster', palette='viridis')\n",
    "plt.title('Agglomerative Clustering with {} distance'.format(metric))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Choose distance metric\n",
    "metric = 'euclidean'  # Change this to 'euclidean', 'minkowski', etc. manhattan\n",
    "\n",
    "# Perform DBSCAN Clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5, metric=metric)\n",
    "labels = dbscan.fit_predict(df)\n",
    "\n",
    "# Add cluster labels to DataFrame\n",
    "df['Cluster'] = labels\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Feature1', y='Feature2',\n",
    "                hue='Cluster', palette='viridis')\n",
    "plt.title('DBSCAN Clustering with {} distance'.format(metric))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
