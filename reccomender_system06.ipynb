{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in original DataFrame:\n",
      "Index(['NOME', 'COGNOME', 'IMPORTO_RICHIESTO', 'TELEFONO', 'CELLULARE',\n",
      "       'TIPO DI OCCUPAZIONE', 'PROVINCIA', 'CONSENSO_DATI_PRIVACY',\n",
      "       'CONSENSO_DATI_MRKTG', 'CONSENSO_DATI_CESSIONE_TERZI', 'SESSO', 'EMAIL',\n",
      "       'REGIONE', 'COMUNE', 'CAP', 'INDIRIZZO', 'CODICE_FISCALE', 'IBAN',\n",
      "       'COMUNE_NASCITA', 'DATA_NASCITA', 'AGE', 'anni lavorativi',\n",
      "       'MOTIVAZIONE_PRESTITO', 'IMPORTO_STIPENDIO_PENSIONE', 'TFR',\n",
      "       'DATA_ ASSUNZIONE_PENSIONAMENTO', 'NOME_AZIENDA', 'TIPO_AZIENDA',\n",
      "       'CODICE_FISCALE_AZIENDA', 'PARTITA_IVA_AZIENDA', 'TEMPO_INDETERMINATO',\n",
      "       'PREVENTIVI_CONCORRENZA', 'TRATTENUTE_BUSTA_PAGA_PENSIONE',\n",
      "       'ALTRI_FINANZIAMENTI_ PRESENTI', 'DOCUMENTAZIONE_PENSIONATO',\n",
      "       'REGISTRAZIONE_TEL_PRIMO_CONTATTO', 'NOTE_LAVORAZIONE_CONTATTO'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   IMPORTO_RICHIESTO             15000 non-null  int64 \n",
      " 1   TIPO DI OCCUPAZIONE           15000 non-null  object\n",
      " 2   PROVINCIA                     14747 non-null  object\n",
      " 3   CONSENSO_DATI_PRIVACY         15000 non-null  object\n",
      " 4   CONSENSO_DATI_MRKTG           15000 non-null  object\n",
      " 5   CONSENSO_DATI_CESSIONE_TERZI  15000 non-null  object\n",
      " 6   SESSO                         15000 non-null  object\n",
      " 7   REGIONE                       15000 non-null  object\n",
      " 8   COMUNE                        14747 non-null  object\n",
      " 9   AGE                           15000 non-null  int64 \n",
      " 10  anni lavorativi               15000 non-null  int64 \n",
      " 11  MOTIVAZIONE_PRESTITO          15000 non-null  object\n",
      " 12  TIPO_AZIENDA                  15000 non-null  object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "# file_path = 'data_simulation_new1.csv'\n",
    "file_path = 'data_simulation_new1.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verify the column presence before any processing\n",
    "print(\"\\nColumns in original DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "'''\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME',\n",
    "                 'COGNOME',\n",
    "                 'TELEFONO',\n",
    "                 'CELLULARE',\n",
    "                 'EMAIL',\n",
    "                 'CAP',\n",
    "                 'INDIRIZZO',\n",
    "                 'CODICE_FISCALE',\n",
    "                 'IBAN',\n",
    "                 'COMUNE_NASCITA',\n",
    "                 'DATA_NASCITA',\n",
    "                 'TFR',\n",
    "                 'NOME_AZIENDA',\n",
    "                 'CODICE_FISCALE_AZIENDA',\n",
    "                 'PARTITA_IVA_AZIENDA',\n",
    "                 'DOCUMENTAZIONE_PENSIONATO',\n",
    "                 'REGISTRAZIONE_TEL_PRIMO_CONTATTO',\n",
    "                 'NOTE_LAVORAZIONE_CONTATTO'\n",
    "                 ], inplace=True)\n",
    "'''\n",
    "\n",
    "\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME',\n",
    "                 'COGNOME',\n",
    "                 'TELEFONO',\n",
    "                 'CELLULARE',\n",
    "                 'EMAIL',\n",
    "                 'CAP',\n",
    "                 'INDIRIZZO',\n",
    "                 'CODICE_FISCALE',\n",
    "                 'IBAN',\n",
    "                 'COMUNE_NASCITA',\n",
    "                 'DATA_NASCITA',\n",
    "                 'IMPORTO_STIPENDIO_PENSIONE',\n",
    "                 'TFR',\n",
    "                 'DATA_ ASSUNZIONE_PENSIONAMENTO',\n",
    "                 'NOME_AZIENDA',\n",
    "                 'CODICE_FISCALE_AZIENDA',\n",
    "                 'PARTITA_IVA_AZIENDA',\n",
    "                 'TEMPO_INDETERMINATO',\n",
    "                 'PREVENTIVI_CONCORRENZA',\n",
    "                 'TRATTENUTE_BUSTA_PAGA_PENSIONE',\n",
    "                 'ALTRI_FINANZIAMENTI_ PRESENTI',\n",
    "                 'DOCUMENTAZIONE_PENSIONATO',\n",
    "                 'REGISTRAZIONE_TEL_PRIMO_CONTATTO',\n",
    "                 'NOTE_LAVORAZIONE_CONTATTO'\n",
    "                 ], inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "399/399 [==============================] - 5s 7ms/step - loss: 3.7434 - accuracy: 0.0665 - val_loss: 2.9009 - val_accuracy: 0.0667\n",
      "Epoch 2/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8958 - accuracy: 0.0798 - val_loss: 2.8805 - val_accuracy: 0.0716\n",
      "Epoch 3/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8779 - accuracy: 0.0824 - val_loss: 2.8767 - val_accuracy: 0.0796\n",
      "Epoch 4/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8734 - accuracy: 0.0817 - val_loss: 2.8814 - val_accuracy: 0.0720\n",
      "Epoch 5/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8716 - accuracy: 0.0795 - val_loss: 2.8778 - val_accuracy: 0.0787\n",
      "Epoch 6/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8697 - accuracy: 0.0818 - val_loss: 2.8727 - val_accuracy: 0.0791\n",
      "Epoch 7/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8675 - accuracy: 0.0802 - val_loss: 2.8718 - val_accuracy: 0.0822\n",
      "Epoch 8/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8661 - accuracy: 0.0845 - val_loss: 2.8714 - val_accuracy: 0.0796\n",
      "Epoch 9/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8668 - accuracy: 0.0848 - val_loss: 2.8747 - val_accuracy: 0.0769\n",
      "Epoch 10/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8643 - accuracy: 0.0859 - val_loss: 2.8706 - val_accuracy: 0.0796\n",
      "Epoch 11/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8626 - accuracy: 0.0872 - val_loss: 2.8677 - val_accuracy: 0.0840\n",
      "Epoch 12/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8616 - accuracy: 0.0871 - val_loss: 2.8711 - val_accuracy: 0.0787\n",
      "Epoch 13/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8618 - accuracy: 0.0875 - val_loss: 2.8655 - val_accuracy: 0.0787\n",
      "Epoch 14/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8622 - accuracy: 0.0845 - val_loss: 2.8690 - val_accuracy: 0.0782\n",
      "Epoch 15/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8607 - accuracy: 0.0874 - val_loss: 2.8669 - val_accuracy: 0.0791\n",
      "Epoch 16/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8600 - accuracy: 0.0888 - val_loss: 2.8675 - val_accuracy: 0.0796\n",
      "Epoch 17/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8603 - accuracy: 0.0890 - val_loss: 2.8650 - val_accuracy: 0.0796\n",
      "Epoch 18/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8596 - accuracy: 0.0903 - val_loss: 2.8657 - val_accuracy: 0.0796\n",
      "Epoch 19/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8593 - accuracy: 0.0894 - val_loss: 2.8662 - val_accuracy: 0.0796\n",
      "Epoch 20/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8605 - accuracy: 0.0893 - val_loss: 2.8671 - val_accuracy: 0.0796\n",
      "Epoch 21/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8590 - accuracy: 0.0894 - val_loss: 2.8642 - val_accuracy: 0.0796\n",
      "Epoch 22/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8589 - accuracy: 0.0896 - val_loss: 2.8652 - val_accuracy: 0.0796\n",
      "Epoch 23/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8587 - accuracy: 0.0896 - val_loss: 2.8668 - val_accuracy: 0.0796\n",
      "Epoch 24/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8595 - accuracy: 0.0893 - val_loss: 2.8653 - val_accuracy: 0.0796\n",
      "Epoch 25/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8600 - accuracy: 0.0892 - val_loss: 2.8642 - val_accuracy: 0.0796\n",
      "Epoch 26/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8599 - accuracy: 0.0899 - val_loss: 2.8640 - val_accuracy: 0.0796\n",
      "Epoch 27/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8594 - accuracy: 0.0895 - val_loss: 2.8659 - val_accuracy: 0.0796\n",
      "Epoch 28/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8592 - accuracy: 0.0896 - val_loss: 2.8651 - val_accuracy: 0.0796\n",
      "Epoch 29/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8587 - accuracy: 0.0896 - val_loss: 2.8663 - val_accuracy: 0.0796\n",
      "Epoch 30/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8595 - accuracy: 0.0896 - val_loss: 2.8663 - val_accuracy: 0.0796\n",
      "Epoch 31/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8587 - accuracy: 0.0896 - val_loss: 2.8648 - val_accuracy: 0.0796\n",
      "Epoch 32/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8584 - accuracy: 0.0895 - val_loss: 2.8691 - val_accuracy: 0.0796\n",
      "Epoch 33/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8587 - accuracy: 0.0896 - val_loss: 2.8649 - val_accuracy: 0.0796\n",
      "Epoch 34/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8583 - accuracy: 0.0896 - val_loss: 2.8649 - val_accuracy: 0.0796\n",
      "Epoch 35/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8585 - accuracy: 0.0896 - val_loss: 2.8654 - val_accuracy: 0.0796\n",
      "Epoch 36/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8583 - accuracy: 0.0895 - val_loss: 2.8663 - val_accuracy: 0.0796\n",
      "Epoch 37/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8587 - accuracy: 0.0895 - val_loss: 2.8650 - val_accuracy: 0.0796\n",
      "Epoch 38/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8580 - accuracy: 0.0895 - val_loss: 2.8648 - val_accuracy: 0.0796\n",
      "Epoch 39/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8577 - accuracy: 0.0896 - val_loss: 2.8644 - val_accuracy: 0.0809\n",
      "Epoch 40/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8576 - accuracy: 0.0893 - val_loss: 2.8658 - val_accuracy: 0.0796\n",
      "Epoch 41/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8577 - accuracy: 0.0894 - val_loss: 2.8648 - val_accuracy: 0.0796\n",
      "Epoch 42/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8572 - accuracy: 0.0897 - val_loss: 2.8653 - val_accuracy: 0.0800\n",
      "Epoch 43/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8575 - accuracy: 0.0897 - val_loss: 2.8652 - val_accuracy: 0.0809\n",
      "Epoch 44/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8576 - accuracy: 0.0898 - val_loss: 2.8656 - val_accuracy: 0.0800\n",
      "Epoch 45/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8570 - accuracy: 0.0898 - val_loss: 2.8647 - val_accuracy: 0.0796\n",
      "Epoch 46/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8565 - accuracy: 0.0896 - val_loss: 2.8651 - val_accuracy: 0.0796\n",
      "Epoch 47/50\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 2.8565 - accuracy: 0.0893 - val_loss: 2.8673 - val_accuracy: 0.0800\n",
      "Epoch 48/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8555 - accuracy: 0.0900 - val_loss: 2.8717 - val_accuracy: 0.0796\n",
      "Epoch 49/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8561 - accuracy: 0.0897 - val_loss: 2.8663 - val_accuracy: 0.0813\n",
      "Epoch 50/50\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 2.8556 - accuracy: 0.0897 - val_loss: 2.8675 - val_accuracy: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 3ms/step\n",
      "\n",
      "Accuracy: 0.08177777777777778\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        94\n",
      "           1       0.00      0.00      0.00        95\n",
      "           2       0.00      0.00      0.00       108\n",
      "           3       0.08      0.97      0.15       179\n",
      "           4       0.00      0.00      0.00       123\n",
      "           5       0.00      0.00      0.00       124\n",
      "           6       0.00      0.00      0.00       139\n",
      "           7       0.00      0.00      0.00        72\n",
      "           8       0.00      0.00      0.00       123\n",
      "           9       0.00      0.00      0.00       102\n",
      "          10       0.00      0.00      0.00       110\n",
      "          11       0.00      0.00      0.00       114\n",
      "          12       0.11      0.01      0.01       184\n",
      "          13       0.00      0.00      0.00       161\n",
      "          14       0.07      0.06      0.07       167\n",
      "          15       0.00      0.00      0.00       144\n",
      "          16       0.00      0.00      0.00        89\n",
      "          17       0.00      0.00      0.00       122\n",
      "\n",
      "    accuracy                           0.08      2250\n",
      "   macro avg       0.01      0.06      0.01      2250\n",
      "weighted avg       0.02      0.08      0.02      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming df is your DataFrame and it's already loaded\n",
    "# df = pd.read_csv('your_data.csv')  # If you need to load data\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        encoders[column] = le\n",
    "\n",
    "# Split the target variable\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Reshape the data to fit an RNN\n",
    "X_train = np.expand_dims(X_train.values, axis=2).astype('float32')\n",
    "X_test = np.expand_dims(X_test.values, axis=2).astype('float32')\n",
    "\n",
    "# Convert target variable to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Initialize and train the RNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(X_train.shape[1], 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model and encoders\n",
    "model.save('rnn_model.h5')\n",
    "joblib.dump(encoders, 'rnn_encoders.pkl')\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test_classes, y_pred_classes)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 706ms/step\n",
      "\n",
      "Predicted MOTIVAZIONE_PRESTITO for new customer: 3\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted probabilities for each class:\n",
      "                                  0\n",
      "Corsi/Specializzazioni     0.052963\n",
      "Risarcimenti               0.039211\n",
      "acquisto arredamento casa  0.033717\n",
      "acquisto auto/moto         0.091148\n",
      "acquisto immobili          0.064636\n",
      "anticipo prima casa        0.039422\n",
      "consolidamento debiti      0.057074\n",
      "investimenti               0.031484\n",
      "liquidità                  0.066830\n",
      "non specificata            0.044564\n",
      "pagamenti imposte e tasse  0.041235\n",
      "rinegoziazione             0.041217\n",
      "ristrutturazione casa      0.074100\n",
      "spese dentistiche          0.062750\n",
      "spese medico sanitarie     0.083560\n",
      "spese per cerimonie        0.065053\n",
      "spese universitarie        0.050518\n",
      "spese viaggi               0.060519\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "# file_path = 'data_simulation_new1.csv'\n",
    "file_path = 'data_simulation_new1.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verify the column presence before any processing\n",
    "# print(\"\\nColumns in original DataFrame:\")\n",
    "# print(df.columns)\n",
    "\n",
    "\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME',\n",
    "                 'COGNOME',\n",
    "                 'TELEFONO',\n",
    "                 'CELLULARE',\n",
    "                 'EMAIL',\n",
    "                 'CAP',\n",
    "                 'INDIRIZZO',\n",
    "                 'CODICE_FISCALE',\n",
    "                 'IBAN',\n",
    "                 'COMUNE_NASCITA',\n",
    "                 'DATA_NASCITA',\n",
    "                 'IMPORTO_STIPENDIO_PENSIONE',\n",
    "                 'TFR',\n",
    "                 'DATA_ ASSUNZIONE_PENSIONAMENTO',\n",
    "                 'NOME_AZIENDA',\n",
    "                 'CODICE_FISCALE_AZIENDA',\n",
    "                 'PARTITA_IVA_AZIENDA',\n",
    "                 'TEMPO_INDETERMINATO',\n",
    "                 'PREVENTIVI_CONCORRENZA',\n",
    "                 'TRATTENUTE_BUSTA_PAGA_PENSIONE',\n",
    "                 'ALTRI_FINANZIAMENTI_ PRESENTI',\n",
    "                 'DOCUMENTAZIONE_PENSIONATO',\n",
    "                 'REGISTRAZIONE_TEL_PRIMO_CONTATTO',\n",
    "                 'NOTE_LAVORAZIONE_CONTATTO'\n",
    "                 ], inplace=True)\n",
    "\n",
    "\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 11000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Interior Designer',\n",
    "    'PROVINCIA': 'Treviso',\n",
    "    'CONSENSO_DATI_PRIVACY': 'si',\n",
    "    'CONSENSO_DATI_MRKTG': 'no',\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 'no',\n",
    "    'SESSO': 'M',\n",
    "    'REGIONE': 'Veneto',\n",
    "    'COMUNE': 'Treviso',\n",
    "    'AGE': 62,\n",
    "    'anni lavorativi': 37,\n",
    "    'TIPO_AZIENDA': 'Privata'\n",
    "}\n",
    "\n",
    "# Load the trained RNN model and encoders\n",
    "clf_loaded = load_model('rnn_model.h5')\n",
    "encoders_loaded = joblib.load('rnn_encoders.pkl')\n",
    "\n",
    "# Encode the new customer profile using the loaded LabelEncoders\n",
    "for column in new_customer:\n",
    "    if column in encoders_loaded:\n",
    "        if new_customer[column] in encoders_loaded[column].classes_:\n",
    "            new_customer[column] = encoders_loaded[column].transform(\n",
    "                [new_customer[column]])[0]\n",
    "        else:\n",
    "            # Assign an outlier value if the category was not seen during training\n",
    "            new_customer[column] = -1\n",
    "\n",
    "# Convert the new customer profile to a DataFrame\n",
    "new_customer_df = pd.DataFrame([new_customer])\n",
    "\n",
    "# Ensure the new customer dataframe has the same columns as the training set\n",
    "missing_cols = set(X.columns) - set(new_customer_df.columns)\n",
    "for col in missing_cols:\n",
    "    new_customer_df[col] = 0\n",
    "new_customer_df = new_customer_df[X.columns]\n",
    "\n",
    "# Reshape the new customer data to match the input shape of the RNN\n",
    "new_customer_array = np.expand_dims(new_customer_df.values, axis=2).astype('float32')\n",
    "\n",
    "# Predict the MOTIVAZIONE_PRESTITO for the new customer using the loaded model\n",
    "prediction = clf_loaded.predict(new_customer_array)\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "print(f\"\\nPredicted MOTIVAZIONE_PRESTITO for new customer: {predicted_class}\")\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = clf_loaded.predict(new_customer_array)\n",
    "\n",
    "# Convert the probabilities into a DataFrame\n",
    "probabilities_df = pd.DataFrame(\n",
    "    predicted_probabilities, columns=encoders_loaded['MOTIVAZIONE_PRESTITO'].classes_)\n",
    "\n",
    "print(f\"Predicted probabilities for each class:\")\n",
    "print(probabilities_df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 296ms/step\n",
      "\n",
      "Predicted MOTIVAZIONE_PRESTITO for new customer: 3\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted probabilities for each class:\n",
      "                                  0\n",
      "Corsi/Specializzazioni     0.052963\n",
      "Risarcimenti               0.039211\n",
      "acquisto arredamento casa  0.033717\n",
      "acquisto auto/moto         0.091148\n",
      "acquisto immobili          0.064636\n",
      "anticipo prima casa        0.039422\n",
      "consolidamento debiti      0.057074\n",
      "investimenti               0.031484\n",
      "liquidità                  0.066830\n",
      "non specificata            0.044564\n",
      "pagamenti imposte e tasse  0.041235\n",
      "rinegoziazione             0.041217\n",
      "ristrutturazione casa      0.074100\n",
      "spese dentistiche          0.062750\n",
      "spese medico sanitarie     0.083560\n",
      "spese per cerimonie        0.065053\n",
      "spese universitarie        0.050518\n",
      "spese viaggi               0.060519\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = 'data_simulation_new1.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME', 'COGNOME', 'TELEFONO', 'CELLULARE', 'EMAIL', 'CAP',\n",
    "                 'INDIRIZZO', 'CODICE_FISCALE', 'IBAN', 'COMUNE_NASCITA', 'DATA_NASCITA',\n",
    "                 'IMPORTO_STIPENDIO_PENSIONE', 'TFR', 'DATA_ ASSUNZIONE_PENSIONAMENTO',\n",
    "                 'NOME_AZIENDA', 'CODICE_FISCALE_AZIENDA', 'PARTITA_IVA_AZIENDA',\n",
    "                 'TEMPO_INDETERMINATO', 'PREVENTIVI_CONCORRENZA', 'TRATTENUTE_BUSTA_PAGA_PENSIONE',\n",
    "                 'ALTRI_FINANZIAMENTI_ PRESENTI', 'DOCUMENTAZIONE_PENSIONATO',\n",
    "                 'REGISTRAZIONE_TEL_PRIMO_CONTATTO', 'NOTE_LAVORAZIONE_CONTATTO'],\n",
    "        inplace=True)\n",
    "\n",
    "# Define target variable and features\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "\n",
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 11000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Interior Designer',\n",
    "    'PROVINCIA': 'Treviso',\n",
    "    'CONSENSO_DATI_PRIVACY': 'si',\n",
    "    'CONSENSO_DATI_MRKTG': 'no',\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 'no',\n",
    "    'SESSO': 'M',\n",
    "    'REGIONE': 'Veneto',\n",
    "    'COMUNE': 'Treviso',\n",
    "    'AGE': 62,\n",
    "    'anni lavorativi': 37,\n",
    "    'TIPO_AZIENDA': 'Privata'\n",
    "}\n",
    "\n",
    "# Load the trained RNN model and encoders\n",
    "clf_loaded = load_model('rnn_model.h5')\n",
    "encoders_loaded = joblib.load('rnn_encoders.pkl')\n",
    "\n",
    "# Encode the new customer profile using the loaded LabelEncoders\n",
    "for column in new_customer:\n",
    "    if column in encoders_loaded:\n",
    "        if new_customer[column] in encoders_loaded[column].classes_:\n",
    "            new_customer[column] = encoders_loaded[column].transform(\n",
    "                [new_customer[column]])[0]\n",
    "        else:\n",
    "            # Assign an outlier value if the category was not seen during training\n",
    "            new_customer[column] = -1\n",
    "\n",
    "# Convert the new customer profile to a DataFrame\n",
    "new_customer_df = pd.DataFrame([new_customer])\n",
    "\n",
    "# Ensure the new customer dataframe has the same columns as the training set\n",
    "missing_cols = set(X.columns) - set(new_customer_df.columns)\n",
    "for col in missing_cols:\n",
    "    new_customer_df[col] = 0\n",
    "new_customer_df = new_customer_df[X.columns]\n",
    "\n",
    "# Reshape the new customer data to match the input shape of the RNN\n",
    "new_customer_array = np.expand_dims(\n",
    "    new_customer_df.values, axis=2).astype('float32')\n",
    "\n",
    "# Predict the MOTIVAZIONE_PRESTITO for the new customer using the loaded model\n",
    "prediction = clf_loaded.predict(new_customer_array)\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "print(f\"\\nPredicted MOTIVAZIONE_PRESTITO for new customer: {predicted_class}\")\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = clf_loaded.predict(new_customer_array)\n",
    "\n",
    "# Convert the probabilities into a DataFrame\n",
    "probabilities_df = pd.DataFrame(\n",
    "    predicted_probabilities, columns=encoders_loaded['MOTIVAZIONE_PRESTITO'].classes_)\n",
    "\n",
    "print(f\"Predicted probabilities for each class:\")\n",
    "print(probabilities_df.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
