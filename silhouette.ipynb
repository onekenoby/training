{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. The output video is saved as: output_with_silhouette.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained face detector (use Haar cascades or a more advanced model if needed)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')  # Optional, for mouth\n",
    "\n",
    "# Input and output video paths\n",
    "input_video_path = 'myVideo.mp4'\n",
    "output_video_path = 'output_with_silhouette.mp4'\n",
    "\n",
    "# Initialize video capture and get properties\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize VideoWriter to save output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Function to draw silhouette lines\n",
    "def draw_silhouette_lines(frame, face_rect, eyes):\n",
    "    x, y, w, h = face_rect\n",
    "    \n",
    "    # Draw vertical line for head (center of face)\n",
    "    head_center_x = x + w // 2\n",
    "    cv2.line(frame, (head_center_x, y), (head_center_x, y + h), (0, 255, 255), 2)\n",
    "    \n",
    "    # Draw vertical line for neck (estimate slightly below face)\n",
    "    neck_y_start = y + h + 10  # start below the face\n",
    "    neck_y_end = neck_y_start + 30  # length of neck line\n",
    "    cv2.line(frame, (head_center_x, neck_y_start), (head_center_x, neck_y_end), (0, 255, 0), 2)\n",
    "    \n",
    "    # Draw horizontal line for shoulders\n",
    "    shoulder_y = neck_y_end + 10\n",
    "    shoulder_x_start = x - 20  # estimate shoulder width based on face width\n",
    "    shoulder_x_end = x + w + 20\n",
    "    cv2.line(frame, (shoulder_x_start, shoulder_y), (shoulder_x_end, shoulder_y), (255, 0, 255), 2)\n",
    "    \n",
    "    # Draw horizontal line for eyes if detected\n",
    "    if len(eyes) > 0:\n",
    "        eye_y = y + eyes[0][1] + eyes[0][3] // 2  # approximate eye line by taking the center of one eye\n",
    "        cv2.line(frame, (x, eye_y), (x + w, eye_y), (0, 0, 255), 2)\n",
    "\n",
    "# Process video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect face in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Detect eyes within face ROI\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        # Draw silhouette lines on the detected parts\n",
    "        draw_silhouette_lines(frame, (x, y, w, h), eyes)\n",
    "\n",
    "    # Display the frame with silhouette in real-time\n",
    "    cv2.imshow('Silhouette Overlay', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # Press 'q' to exit early if needed\n",
    "\n",
    "    # Write the processed frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete. The output video is saved as:\", output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. The output video is saved as: output_with_silhouette.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load pre-trained face and eye detectors\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Input and output video paths\n",
    "input_video_path = 'myvideo.mp4'\n",
    "output_video_path = 'output_with_silhouette.mp4'\n",
    "\n",
    "# Initialize video capture and get properties\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize VideoWriter to save output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps,\n",
    "                      (frame_width, frame_height))\n",
    "\n",
    "# Function to calculate angle between two points (eyes)\n",
    "\n",
    "\n",
    "def calculate_angle(eye_left, eye_right):\n",
    "    dx = eye_right[0] - eye_left[0]\n",
    "    dy = eye_right[1] - eye_left[1]\n",
    "    angle = math.degrees(math.atan2(dy, dx))\n",
    "    return angle\n",
    "\n",
    "# Function to draw silhouette lines for head (blue) and neck (red)\n",
    "\n",
    "\n",
    "def draw_silhouette_lines(frame, face_rect, angle):\n",
    "    x, y, w, h = face_rect\n",
    "\n",
    "    # Calculate the center of the face for positioning lines\n",
    "    face_center_x = x + w // 2\n",
    "    face_center_y = y + h // 2\n",
    "\n",
    "    # Length of the face (blue) and neck (red) lines\n",
    "    face_line_length = int(h * 0.5)\n",
    "    neck_line_length = int(h * 0.5)\n",
    "\n",
    "    # Calculate the end point for the blue (head) line\n",
    "    face_line_end_x = int(\n",
    "        face_center_x + face_line_length * math.cos(math.radians(angle)))\n",
    "    face_line_end_y = int(\n",
    "        face_center_y + face_line_length * math.sin(math.radians(angle)))\n",
    "\n",
    "    # Draw the blue line for the head, tilted with the head angle\n",
    "    cv2.line(frame, (face_center_x, face_center_y), (face_line_end_x,\n",
    "             face_line_end_y), (255, 0, 0), 2)  # Blue color for head line\n",
    "\n",
    "    # Draw the red line for the neck, vertical below the end of the blue line\n",
    "    neck_start_x = face_line_end_x\n",
    "    neck_start_y = face_line_end_y\n",
    "    neck_line_end_x = neck_start_x  # Keep the neck line vertically aligned\n",
    "    neck_line_end_y = neck_start_y + neck_line_length\n",
    "\n",
    "    cv2.line(frame, (neck_start_x, neck_start_y), (neck_line_end_x,\n",
    "             neck_line_end_y), (0, 0, 255), 2)  # Red color for neck line\n",
    "\n",
    "\n",
    "# Process video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect face in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Detect eyes within face ROI to calculate head inclination\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        # Ensure at least two eyes are detected to determine inclination\n",
    "        if len(eyes) >= 2:\n",
    "            # Get coordinates of the two detected eyes\n",
    "            eye_left = (x + eyes[0][0] + eyes[0][2] // 2,\n",
    "                        y + eyes[0][1] + eyes[0][3] // 2)\n",
    "            eye_right = (x + eyes[1][0] + eyes[1][2] // 2,\n",
    "                         y + eyes[1][1] + eyes[1][3] // 2)\n",
    "\n",
    "            # Calculate the angle of the head tilt\n",
    "            angle = calculate_angle(eye_left, eye_right)\n",
    "\n",
    "            # Draw silhouette lines based on the calculated angle\n",
    "            draw_silhouette_lines(frame, (x, y, w, h), angle)\n",
    "\n",
    "    # Display the frame with silhouette in real-time\n",
    "    cv2.imshow('Silhouette Overlay', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # Press 'q' to exit early if needed\n",
    "\n",
    "    # Write the processed frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete. The output video is saved as:\", output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyimage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
