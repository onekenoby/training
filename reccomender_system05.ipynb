{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in original DataFrame:\n",
      "Index(['NOME', 'COGNOME', 'IMPORTO_RICHIESTO', 'TELEFONO', 'CELLULARE',\n",
      "       'TIPO DI OCCUPAZIONE', 'PROVINCIA', 'CONSENSO_DATI_PRIVACY',\n",
      "       'CONSENSO_DATI_MRKTG', 'CONSENSO_DATI_CESSIONE_TERZI', 'SESSO', 'EMAIL',\n",
      "       'REGIONE', 'COMUNE', 'CAP', 'INDIRIZZO', 'CODICE_FISCALE', 'IBAN',\n",
      "       'COMUNE_NASCITA', 'DATA_NASCITA', 'AGE', 'anni lavorativi',\n",
      "       'MOTIVAZIONE_PRESTITO', 'IMPORTO_STIPENDIO_PENSIONE', 'TFR',\n",
      "       'DATA_ ASSUNZIONE_PENSIONAMENTO', 'NOME_AZIENDA', 'TIPO_AZIENDA',\n",
      "       'CODICE_FISCALE_AZIENDA', 'PARTITA_IVA_AZIENDA', 'TEMPO_INDETERMINATO',\n",
      "       'PREVENTIVI_CONCORRENZA', 'TRATTENUTE_BUSTA_PAGA_PENSIONE',\n",
      "       'ALTRI_FINANZIAMENTI_ PRESENTI', 'DOCUMENTAZIONE_PENSIONATO',\n",
      "       'REGISTRAZIONE_TEL_PRIMO_CONTATTO', 'NOTE_LAVORAZIONE_CONTATTO'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   IMPORTO_RICHIESTO               15000 non-null  int64 \n",
      " 1   TIPO DI OCCUPAZIONE             15000 non-null  object\n",
      " 2   PROVINCIA                       14747 non-null  object\n",
      " 3   CONSENSO_DATI_PRIVACY           15000 non-null  object\n",
      " 4   CONSENSO_DATI_MRKTG             15000 non-null  object\n",
      " 5   CONSENSO_DATI_CESSIONE_TERZI    15000 non-null  object\n",
      " 6   SESSO                           15000 non-null  object\n",
      " 7   REGIONE                         15000 non-null  object\n",
      " 8   COMUNE                          14747 non-null  object\n",
      " 9   AGE                             15000 non-null  int64 \n",
      " 10  anni lavorativi                 15000 non-null  int64 \n",
      " 11  MOTIVAZIONE_PRESTITO            15000 non-null  object\n",
      " 12  IMPORTO_STIPENDIO_PENSIONE      15000 non-null  int64 \n",
      " 13  DATA_ ASSUNZIONE_PENSIONAMENTO  15000 non-null  object\n",
      " 14  TIPO_AZIENDA                    15000 non-null  object\n",
      " 15  TEMPO_INDETERMINATO             15000 non-null  object\n",
      " 16  PREVENTIVI_CONCORRENZA          15000 non-null  object\n",
      " 17  TRATTENUTE_BUSTA_PAGA_PENSIONE  15000 non-null  object\n",
      " 18  ALTRI_FINANZIAMENTI_ PRESENTI   15000 non-null  object\n",
      "dtypes: int64(4), object(15)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "# file_path = 'data_simulation_new1.csv'\n",
    "file_path = 'data_simulation_new1.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verify the column presence before any processing\n",
    "print(\"\\nColumns in original DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "# Dropping columns that are not useful for the prediction\n",
    "df.drop(columns=['NOME',\n",
    "                 'COGNOME',\n",
    "                 'TELEFONO',\n",
    "                 'CELLULARE',\n",
    "                 'EMAIL',\n",
    "                 'CAP',\n",
    "                 'INDIRIZZO',\n",
    "                 'CODICE_FISCALE',\n",
    "                 'IBAN',\n",
    "                 'COMUNE_NASCITA',\n",
    "                 'DATA_NASCITA',\n",
    "                 'TFR',\n",
    "                 'NOME_AZIENDA',\n",
    "                 'CODICE_FISCALE_AZIENDA',\n",
    "                 'PARTITA_IVA_AZIENDA',\n",
    "                 'DOCUMENTAZIONE_PENSIONATO',\n",
    "                 'REGISTRAZIONE_TEL_PRIMO_CONTATTO',\n",
    "                 'NOTE_LAVORAZIONE_CONTATTO'\n",
    "                 ], inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using LabelEncoder\n",
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        encoders[column] = le\n",
    "\n",
    "\n",
    "# Split the target variable\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "# clf = RandomForestClassifier('bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2,'min_samples_split': 10, 'n_estimators': 200)\n",
    "clf = RandomForestClassifier(bootstrap=True, max_depth=5,\n",
    "                             min_samples_leaf=2, min_samples_split=5, n_estimators=200)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Save the trained model to a binary file\n",
    "joblib.dump(clf, 'random_forest_model.pkl')\n",
    "joblib.dump(encoders, 'encoders.pkl')\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "feature_importances = pd.DataFrame(\n",
    "    {'feature': X.columns, 'importance': importances})\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# Use zero_division=0 to handle the warning\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.072\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        59\n",
      "           1       0.00      0.00      0.00        68\n",
      "           2       0.00      0.00      0.00        84\n",
      "           3       0.07      1.00      0.13       108\n",
      "           4       0.00      0.00      0.00        80\n",
      "           5       0.00      0.00      0.00        84\n",
      "           6       0.00      0.00      0.00        89\n",
      "           7       0.00      0.00      0.00        50\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.00      0.00      0.00        77\n",
      "          11       0.00      0.00      0.00        78\n",
      "          12       0.00      0.00      0.00       121\n",
      "          13       0.00      0.00      0.00       111\n",
      "          14       0.00      0.00      0.00       120\n",
      "          15       0.00      0.00      0.00        94\n",
      "          16       0.00      0.00      0.00        54\n",
      "          17       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.07      1500\n",
      "   macro avg       0.00      0.06      0.01      1500\n",
      "weighted avg       0.01      0.07      0.01      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Assuming df is your DataFrame and it's already loaded\n",
    "# df = pd.read_csv('your_data.csv')  # If you need to load data\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        encoders[column] = le\n",
    "\n",
    "# Split the target variable\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# Initialize and train the MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(600,100), max_iter=600, random_state=42,activation='relu')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a binary file\n",
    "joblib.dump(clf, 'mlp_model.pkl')\n",
    "joblib.dump(encoders, 'mlp_encoders.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 7ms/step - loss: 33.5950 - accuracy: 0.0541 - val_loss: 8.9992 - val_accuracy: 0.0471\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.4790 - accuracy: 0.0633 - val_loss: 3.9582 - val_accuracy: 0.0708\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 3.1426 - accuracy: 0.0827 - val_loss: 2.8756 - val_accuracy: 0.0877\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8685 - accuracy: 0.0881 - val_loss: 2.8670 - val_accuracy: 0.0879\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8632 - accuracy: 0.0883 - val_loss: 2.8637 - val_accuracy: 0.0879\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8614 - accuracy: 0.0883 - val_loss: 2.8624 - val_accuracy: 0.0879\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8620 - val_accuracy: 0.0879\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8619 - val_accuracy: 0.0879\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8618 - val_accuracy: 0.0879\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8608 - accuracy: 0.0883 - val_loss: 2.8618 - val_accuracy: 0.0879\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8619 - val_accuracy: 0.0879\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8618 - val_accuracy: 0.0879\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8613 - val_accuracy: 0.0879\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8614 - val_accuracy: 0.0879\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8614 - val_accuracy: 0.0879\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8614 - val_accuracy: 0.0879\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8614 - val_accuracy: 0.0879\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8611 - accuracy: 0.0883 - val_loss: 2.8617 - val_accuracy: 0.0879\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8616 - val_accuracy: 0.0879\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8611 - accuracy: 0.0883 - val_loss: 2.8614 - val_accuracy: 0.0879\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8609 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.8610 - accuracy: 0.0883 - val_loss: 2.8615 - val_accuracy: 0.0879\n",
      "  1/235 [..............................] - ETA: 20s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\anaconda3\\envs\\py3aai\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 1s 2ms/step\n",
      "\n",
      "Accuracy: 0.08786666666666666\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       314\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.00      0.00      0.00       338\n",
      "           3       0.09      1.00      0.16       659\n",
      "           4       0.00      0.00      0.00       456\n",
      "           5       0.00      0.00      0.00       362\n",
      "           6       0.00      0.00      0.00       479\n",
      "           7       0.00      0.00      0.00       240\n",
      "           8       0.00      0.00      0.00       415\n",
      "           9       0.00      0.00      0.00       355\n",
      "          10       0.00      0.00      0.00       360\n",
      "          11       0.00      0.00      0.00       332\n",
      "          12       0.00      0.00      0.00       586\n",
      "          13       0.00      0.00      0.00       539\n",
      "          14       0.00      0.00      0.00       543\n",
      "          15       0.00      0.00      0.00       463\n",
      "          16       0.00      0.00      0.00       351\n",
      "          17       0.00      0.00      0.00       406\n",
      "\n",
      "    accuracy                           0.09      7500\n",
      "   macro avg       0.00      0.06      0.01      7500\n",
      "weighted avg       0.01      0.09      0.01      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming df is your DataFrame and it's already loaded\n",
    "# df = pd.read_csv('your_data.csv')  # If you need to load data\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        encoders[column] = le\n",
    "\n",
    "# Split the target variable\n",
    "y = df['MOTIVAZIONE_PRESTITO']\n",
    "X = df.drop(columns=['MOTIVAZIONE_PRESTITO'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)\n",
    "\n",
    "# Reshape the data to fit a CNN\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# Convert target variable to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Initialize and train the CNN\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=1,validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model and encoders\n",
    "model.save('cnn_model.h5')\n",
    "joblib.dump(encoders, 'cnn_encoders.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test_classes, y_pred_classes)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted MOTIVAZIONE_PRESTITO for new customer: 13\n",
      "Predicted loan motivation for the new customer: [0.04138704 0.03289137 0.04580072 0.08365169 0.05190229 0.05124269\n",
      " 0.07431814 0.02794732 0.04558194 0.04361251 0.03986902 0.05099939\n",
      " 0.07932215 0.09944855 0.07660744 0.05589893 0.0442191  0.05529971]\n",
      "Probabilities for each class:\n",
      "                                  0\n",
      "Corsi/Specializzazioni     0.041387\n",
      "Risarcimenti               0.032891\n",
      "acquisto arredamento casa  0.045801\n",
      "acquisto auto/moto         0.083652\n",
      "acquisto immobili          0.051902\n",
      "anticipo prima casa        0.051243\n",
      "consolidamento debiti      0.074318\n",
      "investimenti               0.027947\n",
      "liquiditÃ                   0.045582\n",
      "non specificata            0.043613\n",
      "pagamenti imposte e tasse  0.039869\n",
      "rinegoziazione             0.050999\n",
      "ristrutturazione casa      0.079322\n",
      "spese dentistiche          0.099449\n",
      "spese medico sanitarie     0.076607\n",
      "spese per cerimonie        0.055899\n",
      "spese universitarie        0.044219\n",
      "spese viaggi               0.055300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 19000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Insegnante',\n",
    "    'PROVINCIA': 'Roma',\n",
    "    'CONSENSO_DATI_PRIVACY': 'si',\n",
    "    'CONSENSO_DATI_MRKTG': 'si',\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 'si',\n",
    "    'SESSO': 'F',\n",
    "    'REGIONE': 'Lazio',\n",
    "    'IMPORTO_STIPENDIO_PENSIONE': 3000,\n",
    "    # 'AGE_Category': '41-50',\n",
    "    'anni_lavorativi_Category': '41',\n",
    "    # 'TFR_Category': \"Basso\",\n",
    "    'TIPO_AZIENDA': 'Privata',\n",
    "    'TEMPO_INDETERMINATO': 'no',\n",
    "    # 'PREVENTIVI_CONCORRENZA': 0,\n",
    "    # 'TRATTENUTE_BUSTA_PAGA_PENSIONE': 0,\n",
    "    'ALTRI_FINANZIAMENTI_PRESENTI': 'no'\n",
    "}\n",
    "\n",
    "\n",
    "# Load the trained model and encoders\n",
    "clf_loaded = joblib.load('random_forest_model.pkl')\n",
    "encoders_loaded = joblib.load('encoders.pkl')\n",
    "\n",
    "# Encode the new customer profile using the loaded LabelEncoders\n",
    "for column in new_customer:\n",
    "    if column in encoders_loaded:\n",
    "        new_customer[column] = encoders_loaded[column].transform(\n",
    "            [new_customer[column]])[0]\n",
    "\n",
    "# Convert the new customer profile to a DataFrame\n",
    "new_customer_df = pd.DataFrame([new_customer])\n",
    "\n",
    "# Ensure the new customer dataframe has the same columns as the training set\n",
    "missing_cols = set(X.columns) - set(new_customer_df.columns)\n",
    "for col in missing_cols:\n",
    "    new_customer_df[col] = 0\n",
    "new_customer_df = new_customer_df[X.columns]\n",
    "\n",
    "# Predict the MOTIVAZIONE_PRESTITO for the new customer using the loaded model\n",
    "prediction = clf_loaded.predict(new_customer_df)\n",
    "print(f\"\\nPredicted MOTIVAZIONE_PRESTITO for new customer: {prediction[0]}\")\n",
    "\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = clf.predict_proba(new_customer_df)\n",
    "\n",
    "# Convert the probabilities into a DataFrame\n",
    "probabilities_df = pd.DataFrame(\n",
    "    predicted_probabilities, columns=encoders['MOTIVAZIONE_PRESTITO'].classes_)\n",
    "\n",
    "print(\n",
    "    f\"Predicted loan motivation for the new customer: {predicted_probabilities[0]}\")\n",
    "\n",
    "print(\"Probabilities for each class:\")\n",
    "print(probabilities_df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Poliziotto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m new_customer_df \u001b[38;5;241m=\u001b[39m new_customer_df[X\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Reshape the new customer data to match the input shape of the CNN\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m new_customer_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_customer_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Predict the MOTIVAZIONE_PRESTITO for the new customer using the loaded model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m prediction \u001b[38;5;241m=\u001b[39m clf_loaded\u001b[38;5;241m.\u001b[39mpredict(new_customer_array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Poliziotto'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Example new customer profile\n",
    "new_customer = {\n",
    "    'IMPORTO_RICHIESTO': 19000,\n",
    "    'TIPO DI OCCUPAZIONE': 'Poliziotto',\n",
    "    'PROVINCIA': 'Roma',\n",
    "    'CONSENSO_DATI_PRIVACY': 'si',\n",
    "    'CONSENSO_DATI_MRKTG': 'si',\n",
    "    'CONSENSO_DATI_CESSIONE_TERZI': 'si',\n",
    "    'SESSO': 'F',\n",
    "    'REGIONE': 'Lazio',\n",
    "    'IMPORTO_STIPENDIO_PENSIONE': 3000,\n",
    "    # 'AGE_Category': '41-50',\n",
    "    'anni_lavorativi_Category': '41',\n",
    "    # 'TFR_Category': \"Basso\",\n",
    "    'TIPO_AZIENDA': 'Privata',\n",
    "    'TEMPO_INDETERMINATO': 'no',\n",
    "    # 'PREVENTIVI_CONCORRENZA': 0,\n",
    "    # 'TRATTENUTE_BUSTA_PAGA_PENSIONE': 0,\n",
    "    'ALTRI_FINANZIAMENTI_PRESENTI': 'no'\n",
    "}\n",
    "\n",
    "# Load the trained CNN model and encoders\n",
    "clf_loaded = load_model('cnn_model.h5')\n",
    "encoders_loaded = joblib.load('cnn_encoders.pkl')\n",
    "\n",
    "# Encode the new customer profile using the loaded LabelEncoders\n",
    "for column in new_customer:\n",
    "    if column in encoders_loaded:\n",
    "        new_customer[column] = encoders_loaded[column].transform([new_customer[column]])[0]\n",
    "\n",
    "# Convert the new customer profile to a DataFrame\n",
    "new_customer_df = pd.DataFrame([new_customer])\n",
    "\n",
    "# Ensure the new customer dataframe has the same columns as the training set\n",
    "missing_cols = set(X.columns) - set(new_customer_df.columns)\n",
    "for col in missing_cols:\n",
    "    new_customer_df[col] = 0\n",
    "new_customer_df = new_customer_df[X.columns]\n",
    "\n",
    "# Reshape the new customer data to match the input shape of the CNN\n",
    "new_customer_array = np.expand_dims(new_customer_df.values, axis=2).astype('float32')\n",
    "\n",
    "# Predict the MOTIVAZIONE_PRESTITO for the new customer using the loaded model\n",
    "prediction = clf_loaded.predict(new_customer_array)\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "print(f\"\\nPredicted MOTIVAZIONE_PRESTITO for new customer: {predicted_class}\")\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = clf_loaded.predict(new_customer_array)\n",
    "\n",
    "# Convert the probabilities into a DataFrame\n",
    "probabilities_df = pd.DataFrame(\n",
    "    predicted_probabilities, columns=encoders_loaded['MOTIVAZIONE_PRESTITO'].classes_)\n",
    "\n",
    "print(f\"Predicted loan motivation probabilities for the new customer:\")\n",
    "print(probabilities_df.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
